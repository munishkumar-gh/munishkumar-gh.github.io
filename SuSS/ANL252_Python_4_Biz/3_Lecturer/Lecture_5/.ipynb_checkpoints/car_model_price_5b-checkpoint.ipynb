{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Car sales program:\n",
    "##### Carry out the following tasks in JupyterLab using the prepared DataFrame from the previous chapter:\n",
    "##### Conduct an elbow-test and determine the optimal number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_492/2645489992.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcluster\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Seaborn is another alternative plotting library. \n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_dropmodel_price = pd.read_csv(\"car_dropmodel_price.csv\")\n",
    "car_dropmodel_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, K-Means is an unsupervised machine learning method. This means there is no need for a train-test split. KMeans also allows you to use the ENTIRE dataset.\n",
    "\n",
    "However, 1 thing we need to do is to normalize the data set, but only the numerical variables. We know that Price is the only numerical variable we want to normalize since normalizing year does not make sense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all the Price cells that have NA in them\n",
    "car_clean_price = car_dropmodel_price.dropna(axis = 0, how = \"any\")\n",
    "car_clean_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(car_clean_price[\"Make\"].str.get_dummies(sep=', ').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(car_clean_price[\"Category\"].str.get_dummies(sep=', ').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(car_clean_price[\"Make\"].unique().tolist())\n",
    "print(\"\\n\")\n",
    "print(car_clean_price[\"Category\"].unique().tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What about the non-numerical data? Will that work in K-Means? The answer is NO!\n",
    "\n",
    "##### We have to convert all non-numerical data to binary values using dummy variables.\n",
    "\n",
    "Think about it - how does K-Means (which is based on euclidean distance) know how far the word \"Audi\" is from \"Mercedes\"?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I originally tried this but the outcome was pretty messy. Have a go in any case\n",
    "\n",
    "#X_km = pd.get_dummies(X_km)\n",
    "#X_km_norm = pd.get_dummies(X_km_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "columns_rename1 = { \n",
    "    \"Audi\":1, \"Chevrolet\":2, \"Cadillac\":3, \"Acura\":4, \"BMW\":5, \"Chrysler\":6, \"Ford\":7, \"Buick\":8, \"INFINITI\":9,\n",
    "    \"GMC\":10, \"Honda\":11, \"Hyundai\":12, 'Jeep' : 13, 'Genesis': 14, 'Dodge': 16, 'Jaguar': 17, 'Kia': 18, 'Land Rover': 19,\n",
    "    'Lexus': 20, 'Mercedes-Benz': 21, 'Mitsubishi': 22, 'Lincoln': 23, 'MAZDA': 24, 'Nissan': 25, 'MINI': 26, 'Porsche': 27,\n",
    "    'Ram': 28, 'Subaru': 29, 'Toyota': 30, 'Volkswagen': 31, 'Volvo': 32, 'Alfa Romeo':33\n",
    "}\n",
    "\n",
    "car_clean_price = car_clean_price.replace({'Make':columns_rename1})\n",
    "#print(car_clean_price[\"Make\"].unique().tolist())\n",
    "\n",
    "columns_rename2 = {'SUV':1, 'Sedan':2, 'Coupe':3, 'Pickup':4, 'Van':5, 'Convertible':6, 'Hatchback':7, 'Wagon':8}\n",
    "car_clean_price = car_clean_price.replace({'Category':columns_rename2})\n",
    "#print(car_clean_price[\"Category\"].unique().tolist())\n",
    "\n",
    "car_clean_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_clean_price.to_csv(\"car_clean_price.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here all we are doing is selecting the column we want to normalize; the other steps are just to note the column and row labels\n",
    "numvar_list = ['Price']\n",
    "DF_model_toNorm = car_clean_price[numvar_list]\n",
    "DF_model_toNorm_colnam = list(DF_model_toNorm.columns.values)\n",
    "DF_model_toNorm_rownam = list(DF_model_toNorm.index)\n",
    "DF_model_toNorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This normalizes the data set\n",
    "scaler = preprocessing.StandardScaler()\n",
    "scaler.fit(DF_model_toNorm)\n",
    "DF_model_Norm = scaler.transform(DF_model_toNorm)\n",
    "\n",
    "# Now we convert to a pandas array\n",
    "car_norm_price = pd.DataFrame(DF_model_Norm, columns = DF_model_toNorm_colnam, index = DF_model_toNorm_rownam)\n",
    "car_norm_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we recreate the original dataframe\n",
    "car_norm_price = car_norm_price.add_suffix(\"_norm\")\n",
    "numnormvar_list = car_norm_price.columns.values\n",
    "df_car_final = pd.concat([car_clean_price, car_norm_price], axis = 1)\n",
    "df_car_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First lets drop the normalized values for the elbow plot; the name is stored in \"numnormvar_list\"\n",
    "X_km = df_car_final.drop(numnormvar_list, axis = 1)\n",
    "\n",
    "# This second data set is for once we have optimized the number of clusters\n",
    "X_km_norm = df_car_final.drop(numvar_list, axis = 1)\n",
    "\n",
    "X_km_norm.columns = X_km_norm.columns.str.replace(\"_norm\", \"\")\n",
    "X_km_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Construct a K-Means clustering solution with the number of clusters obtained from the previous task.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets start to do the elbow plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distortions = []\n",
    "\n",
    "min_el = 1\n",
    "max_el = 10\n",
    "\n",
    "# A loop runs thorugh your min and max clusters. \n",
    "# We dont complicate the K-Means at this stage\n",
    "# We store an \"intertia\" number which is the measurement of the distortions in different K clustering solutions\n",
    "\n",
    "for i in range (min_el,max_el):\n",
    "    km = KMeans(n_clusters= i, init = \"k-means++\")\n",
    "    km.fit(X_km)\n",
    "    distortions.append(km.inertia_)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elbow curve\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (5,3), dpi = 150)\n",
    "plt.plot(range (min_el,max_el), distortions, marker='o', markersize=5,\n",
    "    markeredgewidth=2, markeredgecolor='r', markerfacecolor='None')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Average within-cluster sum of squares')\n",
    "plt.title('Elbow for KMeans clustering')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looks like 2 is the optimal number of clusters. Lets do the K means proper now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the K-Means with the optimal number of cluster\n",
    "k = 2\n",
    "km = KMeans(n_clusters=k, init = \"k-means++\", random_state = 0)\n",
    "km_fit = km.fit(X_km_norm)\n",
    "\n",
    "# Predicting the Classificaiton of the Data\n",
    "y_pred = km.fit_predict(X_km_norm)\n",
    "display(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Explore the estimated clustering solution by cross-tabulating the cluster index with the clustering criteria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The predicted results should now be converted to a pandas dataframe\n",
    "\n",
    "y_pred_data = pd.DataFrame({\"cluster\":y_pred},index = X_km_norm.index)\n",
    "y_pred_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_pred = pd.concat([X_km , y_pred_data ], axis = 1)\n",
    "car_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#car_pred[['Price', 'cluster']].groupby(by = ['cluster']).any().transpose()\n",
    "pd.crosstab(car_pred['Price'], car_pred['cluster'], normalize='index', margins = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Plot the clustering solution as a 2-dimensional scatter plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_label0 = car_pred['cluster' == 0]\n",
    "filtered_label1 = car_pred['cluster' == 1]\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 1, ncols = 1, figsize = (5,3), dpi = 150)\n",
    "plt.plot(filtered_label0[:, 0], filtered_label0[:, 1], Price, marker='o', markersize=5,\n",
    "    markeredgewidth=2, markeredgecolor='r', markerfacecolor='None')\n",
    "plt.plot(filtered_label1[:, 0], filtered_label1[:, 1], Price, marker='o', markersize=5,\n",
    "    markeredgewidth=2, markeredgecolor='r', markerfacecolor='None')\n",
    "plt.grid(True)\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Average within-cluster sum of squares')\n",
    "plt.title('Elbow for KMeans clustering')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
