{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc4358d8",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fe4e6b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported\n"
     ]
    }
   ],
   "source": [
    "# Only install the following libraries if you dont have it, otherwise leave it commented out\n",
    "\n",
    "#!conda install -c anaconda natsort --yes\n",
    "#!conda install -c anaconda xlrd --yes\n",
    "\n",
    "#!pip install natsort --user\n",
    "#!pip install xlrd --user\n",
    "#!pip install pycaret[full] --user\n",
    "#!pip install mlflow --user\n",
    "#!pip install tune-sklearn ray[tune] --user\n",
    "#!pip install optuna -- user\n",
    "#!pip install hyperopt --user\n",
    "#!pip install redis --user\n",
    "\n",
    "# General Libraries\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import time\n",
    "import re\n",
    "import requests\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "from natsort import natsorted\n",
    "sns.set()\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sklearn Liraries\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import datetime\n",
    "from datetime import timedelta, date \n",
    "start = time.time()\n",
    "%matplotlib inline\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "# Forces the print statement to show everything and not truncate\n",
    "# np.set_printoptions(threshold=sys.maxsize) \n",
    "print('Libraries imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b122bf21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Receive Data\n",
    "#dir_name = r'C:\\Users\\kswaminathan\\OneDrive\\01_KannaLibrary\\15_Analogs'\n",
    "dir_name = r'C:\\Users\\mkumar\\Documents\\GitHub\\@Papers\\SPE2022\\Final\\1_TORIS_MODEL'\n",
    "filename_suffix = 'csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a7884ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lithology Code</th>\n",
       "      <th>Well Spacing</th>\n",
       "      <th>Net Pay Pay</th>\n",
       "      <th>Gross Pay</th>\n",
       "      <th>Porosity</th>\n",
       "      <th>Swi</th>\n",
       "      <th>Oil FVFi</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Permeability</th>\n",
       "      <th>API Gravity</th>\n",
       "      <th>...</th>\n",
       "      <th>Fractured Faulted</th>\n",
       "      <th>Shale Breaks</th>\n",
       "      <th>Major Gas Cap</th>\n",
       "      <th>Geologic Play</th>\n",
       "      <th>Deposition System</th>\n",
       "      <th>Diagenetic Overprint</th>\n",
       "      <th>Structural Comp</th>\n",
       "      <th>Heterogeniety</th>\n",
       "      <th>Trap Type</th>\n",
       "      <th>URF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>120.0</td>\n",
       "      <td>320.0</td>\n",
       "      <td>600.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>40.0000</td>\n",
       "      <td>1.586</td>\n",
       "      <td>153</td>\n",
       "      <td>10.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.352836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>18.1</td>\n",
       "      <td>35.0000</td>\n",
       "      <td>1.230</td>\n",
       "      <td>163</td>\n",
       "      <td>65.0</td>\n",
       "      <td>35.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.321570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>15.7</td>\n",
       "      <td>51.6333</td>\n",
       "      <td>1.190</td>\n",
       "      <td>185</td>\n",
       "      <td>102.0</td>\n",
       "      <td>32.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "      <td>132</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.277514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>350.0</td>\n",
       "      <td>1400.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1.230</td>\n",
       "      <td>153</td>\n",
       "      <td>3.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>303</td>\n",
       "      <td>131</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>160.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>550.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>35.0000</td>\n",
       "      <td>1.380</td>\n",
       "      <td>200</td>\n",
       "      <td>450.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>302</td>\n",
       "      <td>131</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.425909</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Lithology Code  Well Spacing  Net Pay Pay  Gross Pay  Porosity      Swi  \\\n",
       "0               1         120.0        320.0      600.0      14.0  40.0000   \n",
       "1               1         160.0        100.0      160.0      18.1  35.0000   \n",
       "2               1         160.0        100.0      300.0      15.7  51.6333   \n",
       "3               1          80.0        350.0     1400.0      13.0  30.0000   \n",
       "4               1         160.0        194.0      550.0      23.0  35.0000   \n",
       "\n",
       "   Oil FVFi  Temp  Permeability  API Gravity  ...  Fractured Faulted  \\\n",
       "0     1.586   153          10.0         41.0  ...                  0   \n",
       "1     1.230   163          65.0         35.6  ...                  0   \n",
       "2     1.190   185         102.0         32.9  ...                  0   \n",
       "3     1.230   153           3.0         35.0  ...                  1   \n",
       "4     1.380   200         450.0         27.0  ...                  1   \n",
       "\n",
       "   Shale Breaks  Major Gas Cap  Geologic Play  Deposition System  \\\n",
       "0             0              0            303                132   \n",
       "1             0              0            303                132   \n",
       "2             1              0            303                132   \n",
       "3             1              0            303                131   \n",
       "4             1              1            302                131   \n",
       "\n",
       "   Diagenetic Overprint  Structural Comp  Heterogeniety  Trap Type       URF  \n",
       "0                     1               10              1          2  0.352836  \n",
       "1                     1               10              1          2  0.321570  \n",
       "2                     1               10              1          2  0.277514  \n",
       "3                     1               10              1          2  0.380000  \n",
       "4                     7               10              1          3  0.425909  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skiprows = 0\n",
    "#Means read in the ',' as thousand seperator. Also drops all columns which are unnamed.\n",
    "df = pd.read_excel(\"dfssoil.xlsx\", thousands=',', skiprows = skiprows)\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')] \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9222fa33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lithology Code' 'Well Spacing' 'Net Pay Pay' 'Gross Pay' 'Porosity'\n",
      " 'Swi' 'Oil FVFi' 'Temp' 'Permeability' 'API Gravity' 'Viscosity' 'OOIP'\n",
      " 'Initial GOR' 'Pressure Initial' 'Fractured Faulted' 'Shale Breaks'\n",
      " 'Major Gas Cap' 'Geologic Play' 'Deposition System'\n",
      " 'Diagenetic Overprint' 'Structural Comp' 'Heterogeniety' 'Trap Type'\n",
      " 'URF']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94c2c0d",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "961f18a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Lithology Code  Well Spacing  Net Pay Pay  Gross Pay  Porosity      Swi  \\\n",
      "0               1         120.0        320.0      600.0      14.0  40.0000   \n",
      "1               1         160.0        100.0      160.0      18.1  35.0000   \n",
      "2               1         160.0        100.0      300.0      15.7  51.6333   \n",
      "3               1          80.0        350.0     1400.0      13.0  30.0000   \n",
      "4               1         160.0        194.0      550.0      23.0  35.0000   \n",
      "\n",
      "   Oil FVFi  Temp  Permeability  API Gravity  ...  Pressure Initial  \\\n",
      "0     1.586   153          10.0         41.0  ...            4251.0   \n",
      "1     1.230   163          65.0         35.6  ...            4009.0   \n",
      "2     1.190   185         102.0         32.9  ...            4457.0   \n",
      "3     1.230   153           3.0         35.0  ...            3900.0   \n",
      "4     1.380   200         450.0         27.0  ...            4300.0   \n",
      "\n",
      "   Fractured Faulted  Shale Breaks  Major Gas Cap  Geologic Play  \\\n",
      "0                  0             0              0            303   \n",
      "1                  0             0              0            303   \n",
      "2                  0             1              0            303   \n",
      "3                  1             1              0            303   \n",
      "4                  1             1              1            302   \n",
      "\n",
      "   Deposition System  Diagenetic Overprint  Structural Comp  Heterogeniety  \\\n",
      "0                132                     1               10              1   \n",
      "1                132                     1               10              1   \n",
      "2                132                     1               10              1   \n",
      "3                131                     1               10              1   \n",
      "4                131                     7               10              1   \n",
      "\n",
      "   Trap Type  \n",
      "0          2  \n",
      "1          2  \n",
      "2          2  \n",
      "3          2  \n",
      "4          3  \n",
      "\n",
      "[5 rows x 23 columns]\n",
      "[0.352836   0.32157    0.27751406 0.38       0.425909  ]\n",
      "(317, 23) (317,)\n"
     ]
    }
   ],
   "source": [
    "#Create a copy\n",
    "df_train_test_set=df.copy()\n",
    "\n",
    "Feature = df_train_test_set[[\n",
    "    'Lithology Code', \n",
    "    'Well Spacing',\n",
    "    'Net Pay Pay',\n",
    "    'Gross Pay',\n",
    "    'Porosity', \n",
    "    'Swi',\n",
    "    'Oil FVFi',\n",
    "    'Temp',\n",
    "    'Permeability', \n",
    "    'API Gravity', \n",
    "    'Viscosity',\n",
    "    'OOIP',\n",
    "    'Initial GOR',\n",
    "    'Pressure Initial',\n",
    "    'Fractured Faulted',\n",
    "    'Shale Breaks',\n",
    "    'Major Gas Cap',\n",
    "    'Geologic Play',\n",
    "    'Deposition System',\n",
    "    'Diagenetic Overprint',\n",
    "    'Structural Comp',\n",
    "    'Heterogeniety',\n",
    "    'Trap Type'\n",
    "]]\n",
    "x=Feature\n",
    "\n",
    "y = df_train_test_set['URF'].values\n",
    "\n",
    "print(x.head())\n",
    "print(y[0:5])\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575d91c3",
   "metadata": {},
   "source": [
    "### Train-Test Split 70-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b094c1e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set:  (221, 23) (221,)\n",
      "180      15.0\n",
      "303      46.0\n",
      "266       5.0\n",
      "157       3.0\n",
      "66     1000.0\n",
      "Name: Permeability, dtype: float64\n",
      "Test Set:  (96, 23) (96,)\n",
      "73      50.0\n",
      "280     38.0\n",
      "25      70.0\n",
      "255      5.0\n",
      "9      400.0\n",
      "Name: Permeability, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "random_state = 42\n",
    "test_size = 0.3\n",
    "\n",
    "x_train, x_test, y_train, y_test  = train_test_split(\n",
    "            x, y, test_size = test_size, random_state = random_state\n",
    ")\n",
    "\n",
    "print('Train Set: ', x_train.shape, y_train.shape)\n",
    "print(x_train['Permeability'][0:5])\n",
    "print('Test Set: ', x_test.shape, y_test.shape)\n",
    "print(x_test['Permeability'][0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e34227",
   "metadata": {},
   "source": [
    "### Normalization as per Pycaret z-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "346ad533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standardization X Training Set:  [[-7.12836926e-01 -4.93495232e-01 -6.22497137e-01 -3.73078637e-01\n",
      "  -1.02154633e+00  2.07406413e+00 -2.33349946e-01 -8.84660361e-01\n",
      "  -2.31496028e-01  6.56055401e-01 -7.40229581e-02 -1.98355456e-01\n",
      "  -3.32463525e-01 -7.61729773e-01 -7.38548946e-01 -1.27708746e+00\n",
      "  -4.98585570e-01 -5.54445821e-01 -9.23021962e-01 -6.09101686e-01\n",
      "   2.81501824e+00 -6.71477276e-01 -4.10992682e-01]\n",
      " [-7.12836926e-01  7.02447893e-01 -6.27744681e-01 -6.53129649e-01\n",
      "  -5.12532727e-01 -2.63073147e-01 -1.10331477e+00 -1.67543575e-01\n",
      "  -2.15112018e-01  4.98652572e-01 -7.41421078e-02 -1.81534412e-01\n",
      "  -9.12356315e-01  1.81604030e-01 -7.38548946e-01 -1.27708746e+00\n",
      "  -4.98585570e-01  3.32071741e-01 -1.45396380e+00 -6.09101686e-01\n",
      "  -4.54851202e-01 -6.71477276e-01  1.12848838e+00]\n",
      " [ 2.86754854e+00 -3.56816018e-01  3.89529241e-01 -2.17494741e-01\n",
      "  -7.84795819e-01 -1.58406378e+00  3.29568472e-01 -7.65140897e-01\n",
      "  -2.36781193e-01  9.39024380e-02 -7.42329595e-02 -1.13603274e-01\n",
      "   1.67763505e-01 -2.76013219e-01 -7.38548946e-01  7.83031727e-01\n",
      "   2.00567377e+00 -8.25082371e-01  1.17419829e+00  3.62822304e-01\n",
      "  -4.54851202e-01  8.58383322e-01  1.12848838e+00]\n",
      " [ 1.07735581e+00  7.02447893e-01 -4.80063795e-01  3.22713384e-04\n",
      "  -3.11294789e-01 -5.98438184e-02  7.36964642e-02  1.50572893e+00\n",
      "  -2.37838226e-01  9.39024380e-02 -7.42165764e-02 -4.89069521e-02\n",
      "  -4.96925615e-01  1.16507970e+00 -7.38548946e-01 -1.27708746e+00\n",
      "  -4.98585570e-01  1.60040627e+00  8.82180282e-01  3.62822304e-01\n",
      "  -4.54851202e-01  8.58383322e-01  1.12848838e+00]\n",
      " [-7.12836926e-01 -5.96004643e-01 -3.22637469e-01  9.36730509e-02\n",
      "   1.22758356e+00  2.27729346e+00 -1.00096597e+00 -6.45621433e-01\n",
      "   2.89092675e-01 -1.92984823e+00 -5.94271105e-02 -2.13882573e-01\n",
      "  -1.03236963e+00 -1.40399960e+00  1.35400640e+00 -1.27708746e+00\n",
      "   2.00567377e+00 -2.91123773e-01 -1.53156299e-01 -6.09101686e-01\n",
      "  -4.54851202e-01 -6.71477276e-01 -4.10992682e-01]]\n",
      "Standardization X Testing Set:  [[-0.61847223 -0.18069518  0.66381547  0.34731452 -0.94120199  0.34495916\n",
      "   3.14247988  1.4314872  -0.41690232 -0.3106324  -0.19126635 -0.36980246\n",
      "   2.26978895  1.8994877  -0.77459667 -1.18321596 -0.08928648 -0.23328995\n",
      "   0.03454209 -0.56253004  2.15395568  2.56601161 -0.19726427]\n",
      " [ 1.18071972  1.50123861 -0.25108247 -0.29723989 -0.8490273  -0.63771382\n",
      "   0.51297236 -0.18550836 -0.43190026  1.03163514 -0.19125675 -0.21672092\n",
      "   0.36664638 -0.0449162  -0.77459667 -1.18321596 -0.10570699 -0.11045582\n",
      "   1.94867956  0.70316255 -0.4067842  -0.59215653 -1.65398506]\n",
      " [-0.61847223 -0.8758051   0.58285105  0.02287438  0.09576326  0.54149375\n",
      "   0.31339315  0.99446138 -0.39190576 -0.20996233 -0.19125911 -0.31518302\n",
      "   0.10406657  0.26757728  1.29099445  0.84515425 -0.10570699 -0.23605026\n",
      "   0.03454209 -0.56253004 -0.4067842  -0.59215653 -0.19726427]\n",
      " [-0.61847223  0.23185462 -0.30775757 -0.19341905 -0.48032854  1.03283024\n",
      "   0.31339315 -0.6006829  -0.47314458  0.69606825 -0.19126635 -0.12291704\n",
      "   0.79424526  0.16341279  1.29099445  0.84515425 -0.10570699 -0.76879152\n",
      "   0.00758241  2.39075268  0.87358574 -0.59215653 -1.65398506]\n",
      " [-0.61847223 -0.40283738 -0.2956129  -0.5403537   0.11880693 -0.93251571\n",
      "   1.65077961  1.27852816  0.02053749  0.24864574 -0.19021045  0.04763547\n",
      "   3.35826083  0.87173135 -0.77459667  0.84515425 -0.08928648  2.5077052\n",
      "  -0.77424838 -0.56253004 -0.4067842  -0.59215653 -0.19726427]]\n"
     ]
    }
   ],
   "source": [
    "#https://towardsdatascience.com/data-normalization-with-pandas-and-scikit-learn-7c1cc6ed6475\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_train = preprocessing.StandardScaler().fit(x_train).transform(x_train)\n",
    "X_test = preprocessing.StandardScaler().fit(x_test).transform(x_test)\n",
    "print('Standardization X Training Set: ', X_train[0:5])\n",
    "print('Standardization X Testing Set: ', X_test[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306d214a",
   "metadata": {},
   "source": [
    "### Transformation as per Pycaret 'yeo johnson'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa9943f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed X Training Set:  [[-1.12159764e+00 -7.78502666e-01 -1.00040509e+00 -4.83416109e-01\n",
      "  -1.19896066e+00  1.83426420e+00 -2.57120401e-01 -1.05550717e+00\n",
      "  -4.29107361e-01  7.22299208e-01 -4.29824130e-01 -3.68773577e-01\n",
      "  -3.83742718e-01 -9.51313530e-01 -1.16627752e+00 -7.73246180e-01\n",
      "  -1.11245467e+00 -7.61731931e-01 -9.89205543e-01 -1.02231682e+00\n",
      "   3.86086628e-01 -1.10652962e+00 -3.98464977e-01]\n",
      " [-1.12159764e+00  4.11856079e-01 -1.01243752e+00 -1.00453755e+00\n",
      "  -5.60496483e-01 -2.69148777e-01 -1.62094243e+00 -1.74278723e-01\n",
      "  -3.81688156e-01  5.37917878e-01 -4.31891241e-01 -3.20034305e-01\n",
      "  -1.29475800e+00  1.71162059e-01 -1.16627752e+00 -7.73246180e-01\n",
      "  -1.11245467e+00  2.75283494e-01 -1.60481639e+00 -1.02231682e+00\n",
      "  -9.78308734e-01 -1.10652962e+00  1.21426564e+00]\n",
      " [ 1.00618954e+00 -4.99938710e-01  2.93419690e-01 -2.54141306e-01\n",
      "  -8.92856999e-01 -1.75796147e+00  2.89747411e-01 -8.94733966e-01\n",
      "  -4.45129311e-01  9.54035991e-02 -4.33473577e-01 -1.61673070e-01\n",
      "   1.55885081e-01 -3.01886428e-01 -1.16627752e+00  1.14872405e+00\n",
      "   3.90472424e-01 -1.29334904e+00  1.08165030e+00  2.70548320e-01\n",
      "  -9.78308734e-01  5.05140531e-01  1.21426564e+00]\n",
      " [ 6.20556747e-01  4.11856079e-01 -6.98632270e-01  3.22635460e-04\n",
      "  -3.29573895e-01 -6.01743508e-02  7.14096449e-02  1.16993446e+00\n",
      "  -4.48377292e-01  9.54035991e-02 -4.33187843e-01 -5.68628672e-02\n",
      "  -6.11143375e-01  8.70303192e-01 -1.16627752e+00 -7.73246180e-01\n",
      "  -1.11245467e+00  8.36098106e-01  8.26187335e-01  2.70548320e-01\n",
      "  -9.78308734e-01  5.05140531e-01  1.21426564e+00]\n",
      " [-1.12159764e+00 -1.02401129e+00 -4.18219500e-01  8.75791182e-02\n",
      "   1.02850645e+00  1.99790218e+00 -1.42816456e+00 -7.39242165e-01\n",
      "   1.54975528e-01 -1.55814979e+00 -2.35037457e-01 -4.17633958e-01\n",
      "  -1.52111093e+00 -2.02158565e+00  7.16206701e-01 -7.73246180e-01\n",
      "   3.90472424e-01 -3.47073027e-01 -1.55291609e-01 -1.02231682e+00\n",
      "  -9.78308734e-01 -1.10652962e+00 -3.98464977e-01]]\n",
      "Transformed X Testing Set:  [[-1.11175858 -0.19787736  0.30675174  0.2461565  -1.08528511  0.31973663\n",
      "   1.54362089  1.08339707 -0.74804337 -0.27564044 -0.5569458  -0.65862183\n",
      "   1.11556218  1.23645833 -1.1525394  -0.84767632 -0.23481341 -0.27612452\n",
      "   0.0343964  -1.01307125  0.29683479  0.63203826 -0.19577369]\n",
      " [ 0.52385278  0.89630268 -0.37155261 -0.41396622 -0.96776631 -0.72935299\n",
      "   0.42406014 -0.19502666 -0.79048249  1.47278934 -0.55688661 -0.30567969\n",
      "   0.30740829 -0.04564498 -1.1525394  -0.84767632 -0.33737317 -0.11987086\n",
      "   1.66926908  0.38606626 -0.9613284  -1.09223887 -1.57943867]\n",
      " [-1.11175858 -1.28319621  0.28948271  0.02228027  0.09409343  0.48378394\n",
      "   0.27691802  0.80453575 -0.68018833 -0.19312666 -0.55690113 -0.51705626\n",
      "   0.09849921  0.24499647  0.76264608  1.11468731 -0.33737317 -0.27992345\n",
      "   0.0343964  -1.01307125 -0.9613284  -1.09223887 -0.19577369]\n",
      " [-1.11175858  0.2074488  -0.49607012 -0.24076509 -0.52049522  0.85345555\n",
      "   0.27691802 -0.69567542 -0.91411574  0.89910517 -0.5569458  -0.1496491\n",
      "   0.5674009   0.15454711  0.76264608  1.11468731 -0.33737317 -1.27106274\n",
      "   0.00757531  0.6175167   0.26531052 -1.09223887 -1.57943867]\n",
      " [-1.11175858 -0.48850994 -0.46789254 -0.96503884  0.11626194 -1.12176338\n",
      "   1.03140623  0.98930248  0.01993371  0.27499116 -0.55046462  0.04420059\n",
      "   1.36631161  0.68404894 -1.1525394   1.11468731 -0.23481341  0.92429874\n",
      "  -0.83755206 -1.01307125 -0.9613284  -1.09223887 -0.19577369]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PowerTransformer\n",
    "\n",
    "Xt_train = preprocessing.PowerTransformer(method='yeo-johnson', standardize=False).fit(X_train).transform(X_train)\n",
    "Xt_test = preprocessing.PowerTransformer(method='yeo-johnson', standardize=False).fit(X_test).transform(X_test)\n",
    "print('Transformed X Training Set: ', Xt_train[0:5])\n",
    "print('Transformed X Testing Set: ', Xt_test[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbbb47d",
   "metadata": {},
   "source": [
    "## Note that Ignore Low Variance and Remove Outliers is not implemented as it is assumed it will not make a significant difference to model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "105e0982",
   "metadata": {},
   "source": [
    "### Create a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c9ebbab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conf_mat(cnf_matrix, classes, normalize, cmap, width, height):\n",
    "    plt.figure(figsize=(width, height))\n",
    "    if normalize == True:\n",
    "        # np.newaxis - make it as column vector by inserting an axis \n",
    "        # along second dimension\n",
    "        cnf_matrix = cnf_matrix.astype('float')/ cnf_matrix.sum(\n",
    "            axis=1)[:,np.newaxis]\n",
    "        print(\"Normalized Confusion Matrix\")\n",
    "    else:\n",
    "        print(\"Confusion Matrix, non-normalized\")\n",
    "    \n",
    "    #imshow() - creates image from 2D numpy array.\n",
    "    plt.imshow(cnf_matrix, interpolation = 'nearest', cmap=cmap)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks (tick_marks, classes, rotation=45)\n",
    "    plt.yticks (tick_marks, classes)\n",
    "    \n",
    "    fmt = '.2f'if normalize else 'd'\n",
    "    thres = cnf_matrix.max()/2\n",
    "    for i, j in itertools.product(range(cnf_matrix.shape[0]), range(cnf_matrix.shape[1])):\n",
    "        plt.text(j, i, format(cnf_matrix[i, j], fmt),\n",
    "                 horizontalalignment='center',\n",
    "                 fontsize=20,\n",
    "                 color = 'yellow' if cnf_matrix[i, j] > thres else 'white'\n",
    "                )\n",
    "    # plt.tight_layout()\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.grid(None)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2a9663e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Create a Random Forest Regressor\n",
    "win_rf=RandomForestRegressor(n_estimators=100, criterion=\"mse\", max_depth=None, min_samples_split=2)\n",
    "win_rf.fit(Xt_train, y_train)\n",
    "yhat_rf = win_rf.predict(Xt_test)\n",
    "\n",
    "# # accuracy_score(y_true, y_pred)\n",
    "# mean_acc_rf = accuracy_score(y_test, yhat_rf)\n",
    "# conf_mat_rf = confusion_matrix(y_test, yhat_rf)\n",
    "\n",
    "# print('Random Forest')\n",
    "# print('==============================================\\n')\n",
    "# print(\"True values:\", y_test[0:5].round(1))\n",
    "# print(\"Pred values:\", yhat_rf[0:5].round(1))\n",
    "# print('\\n')\n",
    "# print('Mean Accuracy:', mean_acc_rf)\n",
    "# print('\\n')\n",
    "# print('F1 Score:\\n',classification_report(y_test, yhat_rf))\n",
    "\n",
    "# plot_conf_mat(conf_mat_rf, \n",
    "#               classes=['Wins (0)', \n",
    "#                        'Losses (1)'],\n",
    "#               normalize=normalize, cmap=cmap, width=width, height=height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b12b0393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.1 degrees.\n",
      "Accuracy: 47.85 %.\n"
     ]
    }
   ],
   "source": [
    "errors = abs(yhat_rf - y_test)\n",
    "# Display the performance metrics\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'V/V')\n",
    "mape = np.mean(100 * (errors / y_test))\n",
    "accuracy = 100 - mape\n",
    "print('Accuracy:', round(accuracy, 2), '%.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634ea565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
