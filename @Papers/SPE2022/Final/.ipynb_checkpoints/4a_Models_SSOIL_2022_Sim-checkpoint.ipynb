{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bf28e40",
   "metadata": {},
   "source": [
    "<a href=\"https://www.spe.org/events/en/2022/conference/22apog/asia-pacific-oil-and-gas-conference-and-exhibition.html\"><img src = \"https://www.spe.org/binaries/content/gallery/specms/speevents/organization-logos/spe-logo-2020.png\" width = 200> \n",
    "\n",
    "<h1 align=center><font size = 5>Prediction of Recovery Factor using Machine Learning Methods</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9078d0",
   "metadata": {},
   "source": [
    "<h1 align=center><font size = 4> Munish Kumar, Kannapan Swaminathan</font></h1>\n",
    "<h1 align=center><font size = 4> Part 4: Modelling of Recovery Factor</font></h1>\n",
    "<h1 align=center><font size = 3> ERCE 2022 </font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022d719e",
   "metadata": {},
   "source": [
    "###### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1616885f",
   "metadata": {},
   "source": [
    "1. https://www.kaggle.com/code/kkhandekar/an-introduction-to-pycaret/notebook.\n",
    "2. https://towardsdatascience.com/5-things-you-dont-know-about-pycaret-528db0436eec\n",
    "3. https://www.dataquest.io/blog/understanding-regression-error-metrics/ \n",
    "4. https://www.analyticsvidhya.com/blog/2021/07/automl-using-pycaret-with-a-regression-use-case/\n",
    "5. https://www.datacamp.com/community/tutorials/guide-for-automating-ml-workflows-using-pycaret\n",
    "6. https://pycaret.readthedocs.io/en/latest/api/regression.html\n",
    "7. http://www.pycaret.org/tutorials/html/REG102.html\n",
    "8. https://githubhelp.com/ray-project/tune-sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4477f2be",
   "metadata": {},
   "source": [
    "## Check PyCaret Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b96c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.utils import version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247c5978",
   "metadata": {},
   "outputs": [],
   "source": [
    "version()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ea9670",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e93744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only install the following libraries if you dont have it, otherwise leave it commented out\n",
    "\n",
    "#!conda install -c anaconda natsort --yes\n",
    "#!conda install -c anaconda xlrd --yes\n",
    "\n",
    "#!pip install natsort --user\n",
    "#!pip install xlrd --user\n",
    "#!pip install pycaret[full] --user\n",
    "#!pip install mlflow --user\n",
    "#!pip install tune-sklearn ray[tune] --user\n",
    "#!pip install optuna -- user\n",
    "#!pip install hyperopt --user\n",
    "#!pip install redis --user\n",
    "\n",
    "# General Libraries\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import time\n",
    "import re\n",
    "import requests\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "from natsort import natsorted\n",
    "sns.set()\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sklearn Liraries\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import datetime\n",
    "from datetime import timedelta, date \n",
    "start = time.time()\n",
    "%matplotlib inline\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "# Forces the print statement to show everything and not truncate\n",
    "# np.set_printoptions(threshold=sys.maxsize) \n",
    "print('Libraries imported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4424111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Receive Data\n",
    "#dir_name = r'C:\\Users\\kswaminathan\\OneDrive\\01_KannaLibrary\\15_Analogs'\n",
    "#dir_name = r'C:\\Users\\mkumar\\Documents\\GitHub\\@Papers\\SPE2022\\Final'\n",
    "dir_name = r'C:\\Users\\mkumar\\Documents\\GitHub\\munishkumar-gh.github.io\\@Papers\\SPE2022\\Final'\n",
    "filename_suffix = 'csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3566ed04",
   "metadata": {},
   "source": [
    "##### Read in the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b416f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "skiprows = 0\n",
    "#Means read in the ',' as thousand seperator. Also drops all columns which are unnamed.\n",
    "df = pd.read_excel(\"dftorisv2.xlsx\", thousands=',', skiprows = skiprows)\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')] \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbee492",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot as Heat map to check for highly correlated variables\n",
    "plt.figure(figsize=(15, 15))\n",
    "ax = sns.heatmap(df.corr(), annot=True, fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb8f55ca",
   "metadata": {},
   "source": [
    "In observing the heat map above, I define highly correlated variables as having collinearity coeeficients of > 0.7. There was no highly correlated values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0da5531",
   "metadata": {},
   "source": [
    "##### Convert to float - to ensure it is a numerical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68535e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop = df.copy()\n",
    "df_drop = df_drop.astype(float)\n",
    "\n",
    "# Confirm properties of final dataframe\n",
    "print(len(df_drop))\n",
    "print(df_drop.info())\n",
    "print(df_drop.describe(include='all'))\n",
    "print(df_drop.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7768961",
   "metadata": {},
   "source": [
    "Final Data set has 450 rows and 24 columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0eb8c7a",
   "metadata": {},
   "source": [
    "### Train, Validation, and Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f22b17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a mask where values that are true go into the training/test set\n",
    "# Note that I done it so that the random number is predictable\n",
    "\n",
    "msk = np.random.seed(0)\n",
    "msk = np.random.rand(len(df_drop))<0.8\n",
    "\n",
    "raw_train_validate_set = df_drop[msk]\n",
    "raw_test_set = df_drop[~msk]\n",
    "\n",
    "print(raw_train_validate_set.shape)\n",
    "print(raw_test_set.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f30b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_train_validate_set.to_excel(r'dfssoil.xlsx', index = False, header=True)\n",
    "raw_test_set.to_excel(r'BlindTest_SSOIL.xlsx', index = False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ee3203",
   "metadata": {},
   "source": [
    "We split the data set 80-20 into a \"train-validate\" set and a \"test\" set. The test set is external asn will never be seen by the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8fb589d",
   "metadata": {},
   "source": [
    "## 1. Pycaret Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1d2477",
   "metadata": {},
   "source": [
    "Pycaret will be used in the machine learning portion. Pycaret is a low-code machine learning library in Python that automates machine learning workflows. One of its key benefits is its ability to run a large number of differnt machine learning algorithms, but with only a few lines of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf463969",
   "metadata": {},
   "outputs": [],
   "source": [
    "skiprows = 0\n",
    "#Means read in the ',' as thousand seperator. Also drops all columns which are unnamed.\n",
    "df = pd.read_excel(\"dfssoil.xlsx\", thousands=',', skiprows = skiprows)\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')] \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37193bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.regression import *\n",
    "\n",
    "#Create a copy\n",
    "model_df = df_drop.copy()\n",
    "target = 'URF'\n",
    "\n",
    "# no resampling\n",
    "clf_none = setup(\n",
    "            data=model_df,\n",
    "            target=target,\n",
    "            session_id=42,\n",
    "            normalize=True,\n",
    "            transformation = True,\n",
    "            ignore_low_variance=True,\n",
    "            remove_outliers = True, outliers_threshold = 0.1,\n",
    "            remove_multicollinearity = True, multicollinearity_threshold = 0.7,\n",
    "            train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c249567",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ae6c0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top3 = compare_models(include=['rf', 'catboost', 'knn'], fold = 10, sort='MAE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a04d8d",
   "metadata": {},
   "source": [
    "There is a performance improvement in going from 5 folds to 10 folds for all 3 models. To keep computation time reasonable, folds is kept at 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d893c0",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3562780e",
   "metadata": {},
   "source": [
    "## 3. Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1acd85d0",
   "metadata": {},
   "source": [
    "### a. Tune the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e064830",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583c9e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = create_model('rf', fold = 10)\n",
    "rf = tune_model(rf, \n",
    "                optimize = 'RMSE', \n",
    "                n_iter = 50, \n",
    "                choose_better = True, \n",
    "                 #search_library = \"tune-sklearn\", \n",
    "                 #search_algorithm=\"Hyperopt\",\n",
    "                 #search_algorithm=\"Optuna\",\n",
    "                 #search_algorithm=\"bayesian\",\n",
    "                )\n",
    "tuned_models.append(rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbd7ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = create_model('knn', fold = 10)\n",
    "et = tune_model(knn, \n",
    "                optimize = 'RMSE', \n",
    "                n_iter = 50, \n",
    "                choose_better = True, \n",
    "                 #search_library = \"tune-sklearn\", \n",
    "                 #search_algorithm=\"Hyperopt\",\n",
    "                 #search_algorithm=\"Optuna\",\n",
    "                 #search_algorithm=\"bayesian\",\n",
    "                )\n",
    "tuned_models.append(knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75458831",
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost = create_model('catboost', fold = 10)\n",
    "catboost = tune_model(catboost, \n",
    "                optimize = 'RMSE', \n",
    "                n_iter = 50, \n",
    "                choose_better = True, \n",
    "                 #search_library = \"tune-sklearn\", \n",
    "                 #search_algorithm=\"Hyperopt\",\n",
    "                 #search_algorithm=\"Optuna\",\n",
    "                 #search_algorithm=\"bayesian\",\n",
    "                )\n",
    "tuned_models.append(catboost)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4880257f",
   "metadata": {},
   "source": [
    "## 5. Finalise the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c601d8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_et = finalize_model(knn)\n",
    "#final_et = finalize_model(et)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a321594",
   "metadata": {},
   "source": [
    "### Plots to analyse Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c00ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = final_et\n",
    "predict_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69ef747",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7342d6e",
   "metadata": {},
   "source": [
    "## 6. Blind Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c4f952",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfblind = pd.read_excel(\"BlindTest_SSOIL.xlsx\", thousands=',', skiprows = skiprows)\n",
    "#dfblind = dfblind.loc[:, ~df.columns.str.contains('^Unnamed')] \n",
    "dfblind.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20cf9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BlindPredict = predict_model(final_et, data=dfblind, round=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9841e4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "BlindPredict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c367756d",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = BlindPredict['URF']\n",
    "b = BlindPredict['Label']\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "plt.scatter(a, b, color='blue')\n",
    "plt.plot(a, a, color = 'red', label = 'x=y')\n",
    "plt.xlabel(\"Recovery Factor (%)\", size=14)\n",
    "plt.ylabel(\"Evaluated Recovery Factor (%)\", size=14)\n",
    "\n",
    "#plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23655847",
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 'Completed Process'\n",
    "elapsed = (time.time() - start)\n",
    "print (\"%s in %s seconds\" % (count,elapsed))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
