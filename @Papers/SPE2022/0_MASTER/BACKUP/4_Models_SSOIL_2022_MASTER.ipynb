{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "55b8ca8a",
   "metadata": {},
   "source": [
    "<a href=\"https://www.spe.org/events/en/2022/conference/22apog/asia-pacific-oil-and-gas-conference-and-exhibition.html\"><img src = \"https://www.spe.org/binaries/content/gallery/specms/speevents/organization-logos/spe-logo-2020.png\" width = 200> \n",
    "\n",
    "<h1 align=center><font size = 5>Prediction of Recovery Factor using Machine Learning Methods</font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205a2ddd",
   "metadata": {},
   "source": [
    "<h1 align=center><font size = 4> Munish Kumar, Kannapan Swaminathan</font></h1>\n",
    "<h1 align=center><font size = 4> Part 4: Modelling of Recovery Factor</font></h1>\n",
    "<h1 align=center><font size = 3> ERCE 2022 </font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94935089",
   "metadata": {},
   "source": [
    "###### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf174ec",
   "metadata": {},
   "source": [
    "1. https://www.kaggle.com/code/kkhandekar/an-introduction-to-pycaret/notebook.\n",
    "2. https://towardsdatascience.com/5-things-you-dont-know-about-pycaret-528db0436eec\n",
    "3. https://www.dataquest.io/blog/understanding-regression-error-metrics/ \n",
    "4. https://www.analyticsvidhya.com/blog/2021/07/automl-using-pycaret-with-a-regression-use-case/\n",
    "5. https://www.datacamp.com/community/tutorials/guide-for-automating-ml-workflows-using-pycaret\n",
    "6. https://pycaret.readthedocs.io/en/latest/api/regression.html\n",
    "7. http://www.pycaret.org/tutorials/html/REG102.html\n",
    "8. https://githubhelp.com/ray-project/tune-sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a0b934",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e69eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only install the following libraries if you dont have it, otherwise leave it commented out\n",
    "\n",
    "#!conda install -c anaconda natsort --yes\n",
    "#!conda install -c anaconda xlrd --yes\n",
    "#!pip install pycaret[full] --user\n",
    "#!pip install mlflow --user\n",
    "#!pip install tune-sklearn ray[tune] --user\n",
    "#!pip install optuna -- user\n",
    "#!pip install hyperopt --user\n",
    "\n",
    "# General Libraries\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import time\n",
    "import re\n",
    "import requests\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "from natsort import natsorted\n",
    "sns.set()\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sklearn Liraries\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import datetime\n",
    "from datetime import timedelta, date \n",
    "start = time.time()\n",
    "%matplotlib inline\n",
    "\n",
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "# Forces the print statement to show everything and not truncate\n",
    "# np.set_printoptions(threshold=sys.maxsize) \n",
    "print('Libraries imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6403073",
   "metadata": {},
   "source": [
    "###### Declare some global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611f2c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Receive Data\n",
    "#dir_name = r'C:\\Users\\kswaminathan\\OneDrive\\01_KannaLibrary\\15_Analogs'\n",
    "dir_name = r'C:\\Users\\mkumar\\Documents\\GitHub\\SPE_Paper\\Final'\n",
    "filename_suffix = 'csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67253917",
   "metadata": {},
   "source": [
    "##### Read in the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e645d845",
   "metadata": {},
   "outputs": [],
   "source": [
    "skiprows = 0\n",
    "#Means read in the ',' as thousand seperator. Also drops all columns which are unnamed.\n",
    "df = pd.read_excel(\"dfssoil.xlsx\", thousands=',', skiprows = skiprows)\n",
    "df = df.loc[:, ~df.columns.str.contains('^Unnamed')] \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31b8b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot as Heat map to check for highly correlated variables\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = sns.heatmap(df.corr(), annot=True, fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d85f185e",
   "metadata": {},
   "source": [
    "In observing the heat map above, I define highly correlated variables as having collinearity coeeficients of > 0.7. Therefore,\n",
    "\n",
    "1. 75_ Temperature is highly correlatable to 117_Reservoir top subsea depth\n",
    "2. 77_Pressure is highly correlatable to  117_Reservoir top subsea depth\n",
    "\n",
    "As high collinear variables do not add any additional information when it comes to predictive modelling, I will drop \"117_Reservoir top subsea depth\" and recreate the heat map to check for correlation.\n",
    "\n",
    "Note that dropping the variables makes sense, as reservoir top subsea depth should be physically linked to pressure and temperature in a reservoir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4ea8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop = df.drop(['117_Reservoir top subsea depth (ft TVDSS)',\n",
    "                  ], axis = 1)\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = sns.heatmap(df_drop.corr(), annot=True, fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8b986d",
   "metadata": {},
   "source": [
    "##### Drop Structural Flank Dip - does not make much difference to the results and is a difficult input to find for fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b6758a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop = df_drop.drop(['118_Structural flank dip (average) (deg.)',\n",
    "                  ], axis = 1)\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = sns.heatmap(df_drop.corr(), annot=True, fmt=\".2f\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6d3183",
   "metadata": {},
   "source": [
    "##### Convert EORIOR to float - to ensure it is a numerical feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f6d756",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_drop['EORIOR'] = df_drop['EORIOR'].astype(float)\n",
    "\n",
    "# Confirm properties of final dataframe\n",
    "print(len(df_drop))\n",
    "print(df_drop.info())\n",
    "print(df_drop.describe(include='all'))\n",
    "print(df_drop.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00845086",
   "metadata": {},
   "source": [
    "Final Data set has 436 rows and 19 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afed1c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "fig = px.histogram(df_drop, x=[\"307_Recovery factor (ultimate oil) (%)\"], template = 'plotly_dark', title = 'Histogram of RF')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b94fc2d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# create a copy of data\n",
    "df_drop_copy = df_drop.copy()\n",
    "\n",
    "# create a new feature Log_Price\n",
    "df_drop_copy['Log_RF'] = np.log(df_drop['307_Recovery factor (ultimate oil) (%)'])\n",
    "\n",
    "# plot histogram\n",
    "fig = px.histogram(df_drop_copy, x=[\"Log_RF\"], title = 'Histgram of Log RF', template = 'plotly_dark')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2adfa40",
   "metadata": {},
   "source": [
    "## 1. Pycaret Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0c8f9e",
   "metadata": {},
   "source": [
    "Pycaret will be used in the machine learning portion. Pycaret is a low-code machine learning library in Python that automates machine learning workflows. One of its key benefits is its ability to run a large number of differnt machine learning algorithms, but with only a few lines of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edc493c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.regression import *\n",
    "\n",
    "#Create a copy\n",
    "model_df = df_drop.copy()\n",
    "target = '307_Recovery factor (ultimate oil) (%)'\n",
    "\n",
    "# no resampling\n",
    "clf_none = setup(\n",
    "            data=model_df,\n",
    "            target=target,\n",
    "            session_id=42,\n",
    "            log_experiment = True, \n",
    "            experiment_name = 'RF' \n",
    "            # normalize=True,\n",
    "            # ignore_low_variance=True,\n",
    "            train_size=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3344e4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best = compare_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241d613b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top3_fold_5 = compare_models(include=['rf', 'gbr', 'catboost'], fold = 5, sort='MAE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c1cf41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "top3 = compare_models(include=['rf', 'gbr', 'catboost'], fold = 10, sort='MAE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9572b99b",
   "metadata": {},
   "source": [
    "There is a performance improvement in going from 5 folds to 10 folds for catboost and gbr. However, for rf, 5 folds performs better. However, the improvement is marginal so for simplicity, and to keep computation time reasonable, folds is kept at 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2a2e35",
   "metadata": {},
   "source": [
    "## 2. Plot each Model and Check Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080abfd5",
   "metadata": {},
   "source": [
    "##### Category Boosting (CatBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d259ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "cb = create_model('catboost')\n",
    "cb_results = pull()\n",
    "#print(cb_results)\n",
    "\n",
    "import pandas as pd\n",
    "cb_feature_imp = pd.DataFrame({'Feature': get_config('X_train').columns, 'Value' : abs(cb.feature_importances_)}).sort_values(by='Value', ascending=False)\n",
    "#print(cb_feature_imp)\n",
    "cb_feature_imp.to_csv('Featue_importance_CATBOOST.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9966f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given the sheer number of variables, will only plot the first 10\n",
    "# 'feature_all' will plot everything\n",
    "plot_model(cb, plot = 'feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b1ceb6",
   "metadata": {},
   "source": [
    "##### Random Forest (RFR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1576516c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr = create_model('rf')\n",
    "rfr_results = pull()\n",
    "\n",
    "import pandas as pd\n",
    "rfr_feature_imp = pd.DataFrame({'Feature': get_config('X_train').columns, 'Value' : abs(rfr.feature_importances_)}).sort_values(by='Value', ascending=False)\n",
    "rfr_feature_imp.to_csv('Feature_importance_RFR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad31489",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(rfr, plot = 'feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1154267",
   "metadata": {},
   "source": [
    "##### Gradient Boosting (GBR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238c0c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = create_model('gbr')\n",
    "gbr_results = pull()\n",
    "#print(gbr_results)\n",
    "\n",
    "import pandas as pd\n",
    "gbr_feature_imp = pd.DataFrame({'Feature': get_config('X_train').columns, 'Value' : abs(gbr.feature_importances_)}).sort_values(by='Value', ascending=False)\n",
    "gbr_feature_imp.to_csv('Feature_importance_GBR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27339e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(gbr, plot = 'feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6fad58",
   "metadata": {},
   "source": [
    "## 3a. Testing for Optimisation - Not necessary to run\n",
    "-----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c9c75d",
   "metadata": {},
   "source": [
    "One of the important parameters in the hyperparameters is the number of iterations over which the K fold cross validation is done. \n",
    "\n",
    "2 checks are done for this. The first scenario is over the range(0, 1000, 50). The optimisation ran overnight and showed that the ML algorithm did not see much improvement past 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fd81d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed = []\n",
    "MAE_mean_iter = []\n",
    "MSE_mean_iter = []\n",
    "RMSE_mean_iter = []\n",
    "\n",
    "# The output from the (0, 1000, 50) is saved; there is no need to run this again. \n",
    "# Line has been modified just so the code can run.\n",
    "for i in range(0, 51, 50):\n",
    "    start = time.time()\n",
    "    if i == 0:\n",
    "        i += 1    \n",
    "    tuned_cb = tune_model(cb, optimize = 'MSE', n_iter = i)\n",
    "    #print(tuned_cb)\n",
    "    MAE_mean_iter.append(pull()['MAE']['Mean'])\n",
    "    MSE_mean_iter.append(pull()['MSE']['Mean'])\n",
    "    RMSE_mean_iter.append(pull()['RMSE']['Mean'])\n",
    "    elapsed.append((time.time() - start))\n",
    "\n",
    "MAE_Mean = pd.DataFrame(MAE_mean_iter, index = elapsed, columns=['MAE Mean Error'])\n",
    "MAE_Mean.index.name = 'Elapsed Time'\n",
    "\n",
    "MSE_Mean = pd.DataFrame(MSE_mean_iter, index = elapsed, columns=['MSE Mean Error']) \n",
    "MSE_Mean.index.name = 'Elapsed Time'\n",
    "\n",
    "RMSE_Mean = pd.DataFrame(RMSE_mean_iter, index = elapsed, columns=['RMSE Mean Error'])\n",
    "RMSE_Mean.index.name = 'Elapsed Time'\n",
    "\n",
    "res_50_iter = pd.concat([MAE_Mean, MSE_Mean, RMSE_Mean], axis=1)\n",
    "\n",
    "print(res_50_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca350771",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = sns.lineplot(data=res_50_iter)\n",
    "b.axes.set_title(\"Error as function of Elapsed Time\",fontsize=20)\n",
    "b.set_xlabel(\"Elapsed Time\",fontsize=20)\n",
    "b.set_ylabel(\"Error\",fontsize=20)\n",
    "#b.set_yscale('log')\n",
    "b.tick_params(labelsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743a14e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#res.to_csv('Run_Catboost_1000_Itr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d46476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "elapsed = []\n",
    "MAE_mean_iter = []\n",
    "MSE_mean_iter = []\n",
    "RMSE_mean_iter = []\n",
    "\n",
    "# This was run at (1, 51, 1) to get increments of 1\n",
    "# Right now, this is changed to (1, 51, 50) to allow the code to run efficiently\n",
    "for i in range(1, 51, 50):\n",
    "    start = time.time()\n",
    "    tuned_cb = tune_model(cb, optimize = 'MSE', n_iter = i)\n",
    "    MAE_mean_iter.append(pull()['MAE']['Mean'])\n",
    "    MSE_mean_iter.append(pull()['MSE']['Mean'])\n",
    "    RMSE_mean_iter.append(pull()['RMSE']['Mean'])\n",
    "    elapsed.append((time.time() - start))\n",
    "\n",
    "MAE_Mean = pd.DataFrame(MAE_mean_iter, index = elapsed, columns=['MAE Mean Error'])\n",
    "MAE_Mean.index.name = 'Elapsed Time'\n",
    "\n",
    "MSE_Mean = pd.DataFrame(MSE_mean_iter, index = elapsed, columns=['MSE Mean Error']) \n",
    "MSE_Mean.index.name = 'Elapsed Time'\n",
    "\n",
    "RMSE_Mean = pd.DataFrame(RMSE_mean_iter, index = elapsed, columns=['RMSE Mean Error'])\n",
    "RMSE_Mean.index.name = 'Elapsed Time'\n",
    "\n",
    "res_1_iter = pd.concat([MAE_Mean, MSE_Mean, RMSE_Mean], axis=1)\n",
    "\n",
    "print(res_1_iter)\n",
    "\n",
    "res_1_iter.to_csv('Run_Catboost_50_Itr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb63ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = sns.lineplot(data=res_1_iter)\n",
    "b.axes.set_title(\"Error as function of Elapsed Time\",fontsize=20)\n",
    "b.set_xlabel(\"Elapsed Time\",fontsize=20)\n",
    "b.set_ylabel(\"Error\",fontsize=20)\n",
    "#b.set_yscale('log')\n",
    "b.tick_params(labelsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2527222",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_cb3 = tune_model(cb, optimize = 'RMSE', n_iter = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f569321d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(tuned_cb3, plot = 'parameter')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "706f39dd",
   "metadata": {},
   "source": [
    "##### Gradient Boosting Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a15ae04",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = create_model('gbr')\n",
    "print(gbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3026d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_gbr = tune_model(gbr, search_library = \"tune-sklearn\", search_algorithm=\"hyperopt\", optimize=\"RMSE\", n_iter=50)\n",
    "print(tuned_gbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d69164",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuned_gbr1 = tune_model(gbr, search_library = \"tune-sklearn\", search_algorithm=\"hyperopt\", optimize=\"RMSE\", n_iter=50)\n",
    "#print(tuned_gbr1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8587d173",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuned_gbr4 = tune_model(gbr, search_library = \"tune-sklearn\", search_algorithm=\"optuna\", optimize=\"RMSE\", n_iter=50)\n",
    "#print(tuned_gbr4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb7f065",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuned_gbr5 = tune_model(gbr, search_library = \"tune-sklearn\", search_algorithm=\"bayesian\", optimize=\"RMSE\", n_iter=50)\n",
    "#print(tuned_gbr5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8aa809",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a0e36e",
   "metadata": {},
   "source": [
    "## 3. Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5efe876",
   "metadata": {},
   "source": [
    "### a. Tune the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd77da7",
   "metadata": {},
   "source": [
    "The earlier experiments allow one to determine which model performs efficiently, and the tuning needed to arrive at the answer. Here, we will create the 3 specific models , which we will than blend, and than finally produce a \"tuned\" blended model based on earlier optimised parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4de9e8a",
   "metadata": {},
   "source": [
    "from pycaret.distributions import UniformDistribution, CategoricalDistribution\n",
    "\n",
    "catboost_param_dists = {\n",
    "    'iterations': CategoricalDistribution([500,100,300]),\n",
    "    'colsample_bylevel': UniformDistribution(0.5, 1.0),\n",
    "    'random_strength': CategoricalDistribution([0,0.1,0.2,1,10]),\n",
    "    'max_depth' : CategoricalDistribution([5,6,7,8,9])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99291b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_models = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37e08854",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "cb = create_model('catboost', fold = 10)\n",
    "cb_opt = tune_model(cb, \n",
    "                optimize = 'RMSE', \n",
    "                n_iter = 50, \n",
    "                choose_better = True,\n",
    "                search_library = \"optuna\", \n",
    "                #custom_grid = catboost_param_dists ,\n",
    "                #early_stopping = \"asha\",\n",
    "                #early_stopping_max_iters = 10,\n",
    "                #return_tuner = False ,                \n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57c0da58",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "cb = create_model('catboost', fold = 10)\n",
    "cb_hyp = tune_model(cb, \n",
    "                optimize = 'RMSE', \n",
    "                n_iter = 50, \n",
    "                choose_better = True,\n",
    "                #search_library = \"optuna\", \n",
    "                search_library = \"tune-sklearn\", \n",
    "                search_algorithm=\"hyperopt\",\n",
    "                #custom_grid = catboost_param_dists ,\n",
    "                #early_stopping = \"asha\",\n",
    "                #early_stopping_max_iters = 10,\n",
    "                #return_tuner = False ,                \n",
    "               )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7f22ce",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "cb = create_model('catboost', fold = 10)\n",
    "cb_ran = tune_model(cb, \n",
    "                optimize = 'RMSE', \n",
    "                n_iter = 50, \n",
    "                choose_better = True,\n",
    "                #search_library = \"optuna\", \n",
    "                #search_library = \"tune-sklearn\", \n",
    "                #search_algorithm=\"bayesian\",\n",
    "                #custom_grid = catboost_param_dists ,\n",
    "                #early_stopping = \"asha\",\n",
    "                #early_stopping_max_iters = 10,\n",
    "                #return_tuner = False ,                \n",
    "               )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8799c797",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cb = create_model('catboost', fold = 10)\n",
    "cb = tune_model(cb, \n",
    "                optimize = 'RMSE', \n",
    "                n_iter = 50, \n",
    "                choose_better = True,\n",
    "                search_library = \"tune-sklearn\", \n",
    "                search_algorithm=\"bayesian\",              \n",
    "               )\n",
    "\n",
    "tuned_models.append(cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77a2f166",
   "metadata": {},
   "source": [
    "gbr = create_model('gbr', fold = 10)\n",
    "gbr = tune_model(gbr, \n",
    "                 optimize = 'RMSE', \n",
    "                 n_iter = 50, \n",
    "                 choose_better = True, \n",
    "                 search_library = \"tune-sklearn\", \n",
    "                 search_algorithm=\"Hyperopt\")\n",
    "tuned_models.append(gbr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b186f7",
   "metadata": {},
   "source": [
    "gbr = create_model('gbr', fold = 10)\n",
    "gbr = tune_model(gbr, \n",
    "                 optimize = 'RMSE', \n",
    "                 n_iter = 50, \n",
    "                 choose_better = True, \n",
    "                 search_library = \"tune-sklearn\", \n",
    "                 search_algorithm=\"Optuna\")\n",
    "tuned_models.append(gbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce4a7d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "gbr = create_model('gbr', fold = 10)\n",
    "gbr = tune_model(gbr, \n",
    "                 optimize = 'RMSE', \n",
    "                 n_iter = 50, \n",
    "                 choose_better = True, \n",
    "                 search_library = \"tune-sklearn\", \n",
    "                 search_algorithm=\"bayesian\",\n",
    "                )\n",
    "tuned_models.append(gbr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d9db8a",
   "metadata": {},
   "source": [
    "gbr = create_model('gbr', fold = 10)\n",
    "gbr = tune_model(gbr, \n",
    "                 optimize = 'RMSE', \n",
    "                 n_iter = 50, \n",
    "                 choose_better = True, \n",
    "                 #search_library = \"tune-sklearn\", \n",
    "                 #search_algorithm=\"bayesian\"\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef528d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = create_model('rf', fold = 10)\n",
    "rf = tune_model(rf, \n",
    "                optimize = 'RMSE', \n",
    "                n_iter = 10, \n",
    "                choose_better = True, \n",
    "                search_library = \"tune-sklearn\", \n",
    "                search_algorithm=\"bayesian\")\n",
    "tuned_models.append(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32603121",
   "metadata": {},
   "source": [
    "### b. Ensemble the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074da28a",
   "metadata": {},
   "source": [
    "pycaret.regression.ensemble_model(estimator, method: str = 'Bagging', fold: Optional[Union[int, Any]] = None, n_estimators: int = 10, round: int = 4, choose_better: bool = False, optimize: str = 'R2', fit_kwargs: Optional[dict] = None, groups: Optional[Union[str, Any]] = None, verbose: bool = True, return_train_score: bool = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7875dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_model = []\n",
    "\n",
    "tuned_bagged_cb = ensemble_model(estimator = cb, method = 'Bagging', n_estimators=50, optimize = 'RMSE')\n",
    "prediction_model.append(tuned_bagged_cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b014fae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_boosted_cb = ensemble_model(estimator = cb, method = 'Boosting', n_estimators=50, optimize = 'RMSE')\n",
    "prediction_model.append(tuned_boosted_cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e419dba8",
   "metadata": {},
   "source": [
    "Based on the output here, the 'boosting' method has dropped the MAE, MSE and RMSE from 9.03, 128.5 & 11.32 to 8.89, 122.7 and 11.06 respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b93230",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_bagged_gbr = ensemble_model(estimator = gbr, method = 'Bagging', n_estimators=50, optimize = 'RMSE')\n",
    "prediction_model.append(tuned_bagged_gbr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c172b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_boosted_gbr = ensemble_model(estimator = gbr, method = 'Boosting', n_estimators=50, optimize = 'RMSE')\n",
    "prediction_model.append(tuned_boosted_gbr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6916aa",
   "metadata": {},
   "source": [
    "Based on the output here, none of the methods have improved the MAE, MSE and RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b39cbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_bagged_rf = ensemble_model(estimator = rf, method = 'Bagging', n_estimators=50, optimize = 'RMSE')\n",
    "prediction_model.append(tuned_bagged_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87c2f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_boosted_rf = ensemble_model(estimator = rf, method = 'Boosting', n_estimators=50, optimize = 'RMSE')\n",
    "prediction_model.append(tuned_boosted_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d3cef3",
   "metadata": {},
   "source": [
    "Based on the output here, the 'boosting' method has improved the statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f47623",
   "metadata": {},
   "source": [
    "### c. Blending all Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7867c3cb",
   "metadata": {},
   "source": [
    "pycaret.regression.blend_models(\n",
    "estimator_list: list, fold: Optional[Union[int, Any]] = None, round: int = 4, choose_better: bool = False, optimize: str = 'R2', weights: Optional[List[float]] = None, fit_kwargs: Optional[dict] = None, groups: Optional[Union[str, Any]] = None, verbose: bool = True, return_train_score: bool = False )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea4e45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_5_soft = blend_models(estimator_list = tuned_models, fold=5, optimize = 'RMSE', choose_better = True)\n",
    "prediction_model.append(blend_5_soft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bad616",
   "metadata": {},
   "outputs": [],
   "source": [
    "blend_10_soft = blend_models(estimator_list = tuned_models, fold=10, optimize = 'RMSE', choose_better = True)\n",
    "prediction_model.append(blend_10_soft)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78466307",
   "metadata": {},
   "source": [
    "### d. Stacking all Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dfb754",
   "metadata": {},
   "source": [
    "pycaret.regression.stack_models(estimator_list: list, meta_model=None, meta_model_fold: Optional[Union[int, Any]] = 5, fold: Optional[Union[int, Any]] = None, round: int = 4, restack: bool = True, choose_better: bool = False, optimize: str = 'R2', fit_kwargs: Optional[dict] = None, groups: Optional[Union[str, Any]] = None, verbose: bool = True, return_train_score: bool = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c84f793",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_5 = stack_models(estimator_list = tuned_models, meta_model = cb, fold = 5, optimize = 'RMSE', choose_better= True)\n",
    "prediction_model.append(stack_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11e9aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_10 = stack_models(estimator_list = tuned_models, meta_model = cb, fold = 10, optimize = 'RMSE', choose_better= True)\n",
    "prediction_model.append(stack_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46acd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232a448d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in prediction_model:\n",
    "    print(model.__class__.__name__)\n",
    "    display(predict_model(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b6f5f9",
   "metadata": {},
   "source": [
    "## 4. Save the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e44375",
   "metadata": {},
   "source": [
    "#### Lowest Mean RMSE = 10.99 is \"blend_10_soft\" which is the blending of all models with 10 K-folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba544cc7",
   "metadata": {},
   "source": [
    "save_model(blend_10_soft, 'Blended_model_21042022')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16494d2",
   "metadata": {},
   "source": [
    "#### 2nd Lowest Mean RMSE = 11.06 is \"tuned_boosted_cb\" which is the boosted cat boost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf618947",
   "metadata": {},
   "source": [
    "save_model(tuned_boosted_cb, 'Boosted_CatBoost_21042022')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "244f989c",
   "metadata": {},
   "source": [
    "#### 3rd Lowest Mean RMSE = 11.15 is \"blend_10_soft\" which is the boosted Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3ec0a7",
   "metadata": {},
   "source": [
    "save_model(tuned_boosted_rf, 'Boosted_RF_21042022')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04f9209d",
   "metadata": {},
   "source": [
    "#### 4th Lowest Mean RMSE = 11.19 is \"tuned_boosted_gbr\" which is the boosted gradient boost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb9c265",
   "metadata": {},
   "source": [
    "save_model(tuned_boosted_gbr, 'Boosted_GBR_21042022')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d919f05",
   "metadata": {},
   "source": [
    "## 5. Finalise the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21da1de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_blend = finalize_model(blend_10_soft)\n",
    "save_model(final_blend, 'Blended_model_21042022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac79534",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_db = finalize_model(tuned_boosted_cb)\n",
    "save_model(final_db, 'Boosted_CatBoost_21042022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba86b74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_gbr = finalize_model(tuned_boosted_gbr)\n",
    "save_model(final_gbr, 'Boosted_GBR_21042022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e6771ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_rf = finalize_model(tuned_boosted_rf)\n",
    "save_model(final_rf, 'Boosted_RF_21042022')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a07905",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_model(final_blend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d38c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(final_blend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712312d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(final_blend, plot = 'error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "219ae744",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://towardsdatascience.com/easy-mlops-with-pycaret-mlflow-7fbcbf1e38c6\n",
    "plot_model(final_blend, plot = 'residuals_interactive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6c623f",
   "metadata": {},
   "source": [
    "## 6. Blind Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc2f61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "skiprows = 0\n",
    "dfblind = pd.read_excel(\"BlindTest_SSOIL.xlsx\", sheet_name='Inputs', thousands=',', skiprows = skiprows)\n",
    "#dfblind = dfblind.loc[:, ~df.columns.str.contains('^Unnamed')] \n",
    "dfblind.drop('307_Recovery factor (ultimate oil) (%)', axis=1, inplace=True)\n",
    "dfblind.dropna(axis = 0, inplace=True)\n",
    "\n",
    "dfblind.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a50d30b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "BlindPredict1 = predict_model(final_blend, data=dfblind, round=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa1c0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BlindPredict1 = BlindPredict1.rename(columns={'Label': 'Blended Predicted Recovery factor (ultimate oil) (%)'\n",
    "                                 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a903abf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BlindPredict1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
