{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Part 3: \n",
    "#### This data set is looking at Weather Data collected over a few years. The data set is not totally ready for analysis as there are some outliers that need to be handled. \n",
    "\n",
    "#### After this is done, I will prepare the validation, training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The '2_Weather_Proc' data set includes details of ~460 different monthly time periods, recorded at the Change Climate Station. Here are the fields:\n",
    "\n",
    "| Field          | Description|\n",
    "|----------------|--------------------------------------------------------|\n",
    "| Year-month                | Month and Year of Data Point                |\n",
    "| temp_mean_daily_min       | The monthly and annual mean daily minimum temperature                                                               |\n",
    "| temp_extremes_min         | The absolute extreme minimum air temperature|\n",
    "| temp_mean_daily_max       | The monthly and annual mean daily maximum temperature                                                               |\n",
    "| mean_temp                 | The monthly mean air temperature            |\n",
    "| max_temperature           | The monthly extreme maximum air temperature |\n",
    "| mean_sunshine_hrs         | The monthly mean sunshine hours in a day    |\n",
    "| wet_bulb_temperature      | The hourly wet bulb temperature             |\n",
    "| maximum_rainfall_in_a_day | The highest daily total rainfall            |\n",
    "| total_rainfall            | The total monthly rainfall                  |\n",
    "| rh_extremes_minimum       | The absolute extreme minimum relative humidity                                                                  |\n",
    "| mean_rh                   | The monthly mean relative humidity          |\n",
    "| no_of_rainy_days          | The number of rain days (day with rainfall amount of 0.2mm or more)                                                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General Libraries\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import time\n",
    "import re\n",
    "import requests\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "sns.set()\n",
    "\n",
    "# Sklearn Liraries\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from datetime import timedelta, date \n",
    "start = time.time()\n",
    "%matplotlib inline\n",
    "\n",
    "# Forces the print statement to show everything and not truncate\n",
    "# np.set_printoptions(threshold=sys.maxsize) \n",
    "print('Libraries imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data from CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre_proc = pd.read_csv('2_Weather_Proc.csv')\n",
    "print(df_pre_proc.shape)\n",
    "print(df_pre_proc.info())\n",
    "df_pre_proc.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre_proc.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_pre_proc.tail(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dealing with outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df_pre_proc == 0).astype(int).sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 250 cells in the 'temp_mean_daily_min' column (~50% of the data) which is null (no data was recorded). There are also 55 cells in 'wet_bulb_temperature' which is 0. A \"0\" degree value in tropical Singapore is impossible, meaning these values are outliers that have to be dealt with.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre_proc['temp_mean_daily_min'].dropna().value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 'temp_mean_daily_min', the points mostly lie in the range 24.5 - 25.4 (0.9 degree difference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre_proc['wet_bulb_temperature'].dropna().round(1).value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For 'wet_bulb_temperature', the points mostly lie in the range 24.6 - 26.1 (1.5 degree difference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The small range of data points presents 2 approaches to dealing with this '0' outlier. Either I drop the whole column or I can statistically replace the '0' values with a random number from the range mentioned above. I will apply the latter. \n",
    "\n",
    "This statistical replacement will be done by (a) masking out values that are non-zero and (b) selecting, from a normal distribution, a random number that is then multiplied to another random number uniformly extracted from the range 23.5 to 27.1. This emulates noise while keeping the data within a tight bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rand_gen(a, b, df):\n",
    "    # Pick a random number based on a normal distribution\n",
    "    rand_norm = np.random.normal(1, 0.01, df.shape[0])\n",
    "    rand_uni = np.random.uniform(a, b)\n",
    "    out = rand_norm * rand_uni\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the process to replace the 0-cells in 'temp_mean_daily_min'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean mask, 0 = true\n",
    "mask_1 = df_pre_proc['temp_mean_daily_min'] == 0\n",
    "mask_2 = ~mask_1\n",
    "\n",
    "# All values that are greater than 0 are filtered out\n",
    "df_filt = df_pre_proc[df_pre_proc['temp_mean_daily_min'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the numbers that are the replacement for 0. \n",
    "# np automatically converts boolen (T, F) to (0, 1)\n",
    "df_min = df_pre_proc[df_pre_proc['temp_mean_daily_min'] > 0]['temp_mean_daily_min'].mean()\n",
    "df_max = df_pre_proc[df_pre_proc['temp_mean_daily_min'] > 0]['temp_mean_daily_min'].max()\n",
    "replace_1 = mask_1 * rand_gen(df_min, df_max, df_pre_proc)\n",
    "replace_2 = mask_2 * df_pre_proc['temp_mean_daily_min']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre_proc['temp_mean_daily_min'] = np.maximum(replace_1,replace_2).round(1)\n",
    "df_pre_proc['temp_mean_daily_min']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the process to replace the 0-cells in 'wet_bulb_temperature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean mask, 0 = true\n",
    "mask_3 = df_pre_proc['wet_bulb_temperature'] == 0\n",
    "mask_4 = ~mask_3\n",
    "\n",
    "# All values that are greater than 0 are filtered out\n",
    "df_filt2 = df_pre_proc[df_pre_proc['wet_bulb_temperature'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the numbers that are the replacement for 0. \n",
    "# np automatically converts boolen (T, F) to (0, 1)\n",
    "df_min2 = df_pre_proc[df_pre_proc['wet_bulb_temperature'] > 0]['wet_bulb_temperature'].mean()\n",
    "df_max2 = df_pre_proc[df_pre_proc['wet_bulb_temperature'] > 0]['wet_bulb_temperature'].max()\n",
    "replace_3 = mask_3 * rand_gen(df_min2, df_max2, df_pre_proc)\n",
    "replace_4 = mask_4 * df_pre_proc['wet_bulb_temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre_proc['wet_bulb_temperature'] = np.maximum(replace_3,replace_4).round(1)\n",
    "df_pre_proc['wet_bulb_temperature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pre_proc.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ncols = 3\n",
    "fig, axes = plt.subplots(ncols=ncols)\n",
    "fig.set_figwidth(20)\n",
    "\n",
    "# Plot all Temperature related data for QC\n",
    "sns.distplot(df_pre_proc['temp_mean_daily_min'],\n",
    "             hist = True, ax=axes[0])\n",
    "sns.distplot(df_pre_proc['temp_extremes_min'],\n",
    "             hist = True, ax=axes[0])\n",
    "sns.distplot(df_pre_proc['temp_mean_daily_max'],\n",
    "             hist = True, ax=axes[0])\n",
    "sns.distplot(df_pre_proc['mean_temp'],\n",
    "             hist = True, ax=axes[0])\n",
    "sns.distplot(df_pre_proc['max_temperature'],\n",
    "             hist = True, ax=axes[0])\n",
    "sns.distplot(df_pre_proc['wet_bulb_temperature'],\n",
    "             hist = True, ax=axes[0])\n",
    "\n",
    "# Plot all Rain related data for QC\n",
    "sns.distplot(df_pre_proc['maximum_rainfall_in_a_day'],\n",
    "             hist = True, ax=axes[1])\n",
    "sns.distplot(df_pre_proc['total_rainfall'],\n",
    "             hist = True, ax=axes[1])\n",
    "sns.distplot(df_pre_proc['no_of_rainy_days'],\n",
    "             hist = True, ax=axes[1])\n",
    "\n",
    "# Plot all Humidity related data for QC\n",
    "sns.distplot(df_pre_proc['rh_extremes_minimum'],\n",
    "             hist = True, ax=axes[2])\n",
    "sns.distplot(df_pre_proc['mean_rh'],\n",
    "             hist = True, ax=axes[2])\n",
    "\n",
    "for i in range(ncols):\n",
    "    ax = axes[i]\n",
    "    if i == 0:\n",
    "        ax.set_title('Histogram - Temperature Data Distribution')\n",
    "        ax.set_xlabel('Temperature Data (Deg C)')\n",
    "        ax.set_ylabel('Frequency')\n",
    "    if i == 1:\n",
    "        ax.set_title('Histogram - Rainfall Data Distribution')\n",
    "        ax.set_xlabel('Rainfall Data (Days)')\n",
    "        ax.set_ylabel('Frequency')\n",
    "    if i == 2:\n",
    "        ax.set_title('Histogram - Humidity Data Distribution')\n",
    "        ax.set_xlabel('Humidity Data (%)')\n",
    "        ax.set_ylabel('Frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For empty Dataframe - testing purposes\n",
    "# column_names = [ ]\n",
    "# df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "df_pre_proc['Year-month']=pd.to_datetime(df_pre_proc['Year-month'])\n",
    "\n",
    "df_pre_proc['month'] = df_pre_proc['Year-month'].dt.month\n",
    "df_pre_proc['Year'] = df_pre_proc['Year-month'].dt.year\n",
    "df_pre_proc.drop(['Year-month'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the data set is truly ready for interpretation and use. First, lets split the data set into a training/test set and an evaluation set. The evaluation set will be treated as an \"out-of-sample\" set for the final model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the Data Sets for Predictive Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = np.random.rand(len(df_pre_proc))<0.8\n",
    "train_test_set = df_pre_proc[msk]\n",
    "validate_set = df_pre_proc[~msk]\n",
    "print(train_test_set.shape)\n",
    "print(validate_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Selection on 'train_test_set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature = train_test_set[[\n",
    "    'temp_mean_daily_min', 'temp_extremes_min', 'temp_mean_daily_max', 'mean_temp', \n",
    "    'max_temperature', 'mean_sunshine_hrs', 'wet_bulb_temperature', 'maximum_rainfall_in_a_day', \n",
    "    'total_rainfall', 'rh_extremes_minimum', 'mean_rh', 'month'\n",
    "]]\n",
    "x=Feature\n",
    "x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label data for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_test_set['no_of_rainy_days'].values\n",
    "print(y[0:5])\n",
    "print(x.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I split the 'train_test_set' into a training and testing set. I will do this with a 70-30 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "            x, y, test_size = 0.3, random_state = 42\n",
    ")\n",
    "\n",
    "print('Train Set: ', x_train.shape, y_train.shape)\n",
    "print('Test Set: ', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize Data to give zero mean and unit variance. \n",
    "\n",
    "This is only done to the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=preprocessing.StandardScaler().fit(x_train).transform(x_train)\n",
    "X_test=preprocessing.StandardScaler().fit(x_test).transform(x_test)\n",
    "print('Normalized X Training Set: ', X_train[0:5])\n",
    "print('Normalized X Testing Set: ', X_test[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pickle the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pickle all the training (post normalization) \n",
    "# and testing data sets\n",
    "with open('X_train', 'wb') as file:\n",
    "    pickle.dump(X_train, file)\n",
    "with open('X_test', 'wb') as file:\n",
    "    pickle.dump(X_test, file)\n",
    "with open('y_train', 'wb') as file:\n",
    "    pickle.dump(y_train, file)\n",
    "with open('y_test', 'wb') as file:\n",
    "    pickle.dump(y_test, file)\n",
    "with open('validate_set', 'wb') as file:\n",
    "    pickle.dump(validate_set, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 'Completed Process'\n",
    "elapsed = (time.time() - start)\n",
    "print (\"%s in %s seconds\" % (count,elapsed))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
